{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your dataset\n",
    "data = pd.read_csv(\"mt.csv\")\n",
    "\n",
    "# Separate input features and target values\n",
    "X = data[['F1', 'F2']].values\n",
    "y_class = data['T1'].values.reshape(-1, 1)\n",
    "y_reg = data['T2'].values.reshape(-1, 1)\n",
    "\n",
    "# Split your dataset into training and validation\n",
    "X_train, X_val, y_train_class, y_val_class, y_train_reg, y_val_reg = train_test_split(X, y_class, y_reg, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the multi-task neural network\n",
    "input_size = 2\n",
    "hidden_sizes = [10, 5]\n",
    "output_sizes = [1, 1]\n",
    "learning_rate = 0.01\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sigmoid function\n",
    "def sigmoid(x):\n",
    "    exp = np.exp(-x)\n",
    "    return 1 / (1 + exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "# derivative of sigmoid function\n",
    "def sigmoid_derivative(x):\n",
    "    s = sigmoid(x)\n",
    "    return s * (1 - s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperbolic tangent function\n",
    "def tanh(x):\n",
    "    return np.tanh(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "# derivative of hyperbolic tangent function\n",
    "def tanh_derivative(x):\n",
    "    return 1 - np.tanh(x)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize weights and biases\n",
    "def initialize_weights(input_size, hidden_sizes, output_sizes):\n",
    "    weights = [np.random.randn(input_size, hidden_sizes[0]), np.random.randn(hidden_sizes[0], hidden_sizes[1]), np.random.randn(hidden_sizes[1], output_sizes[0]), np.random.randn(hidden_sizes[1], output_sizes[1])]\n",
    "    biases = [np.zeros((1, hidden_sizes[0])), np.zeros((1, hidden_sizes[1])), np.zeros((1, output_sizes[0])), np.zeros((1, output_sizes[1]))]\n",
    "    return weights, biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forward propagation function\n",
    "def forward_propogation(x, weights, biases):\n",
    "    # Compute the linear combinations of inputs and weights for the first layer\n",
    "    linear_combination_layer_1 = np.dot(x, weights[0]) + biases[0]\n",
    "    # Apply the sigmoid activation function to the first layer output\n",
    "    activation_layer_1 = sigmoid(linear_combination_layer_1)\n",
    "    # Compute the linear combinations of first layer activations and weights for the second layer\n",
    "    linear_combination_layer_2 = np.dot(activation_layer_1, weights[1]) + biases[1]\n",
    "    # Apply the tanh activation function to the second layer output\n",
    "    activation_layer_2 = tanh(linear_combination_layer_2)\n",
    "    # Compute the linear combinations of second layer activations and weights for the output layer - classification task\n",
    "    linear_combination_classification = np.dot(activation_layer_2, weights[2]) + biases[2]\n",
    "    # Compute the linear combinations of second layer activations and weights for the output layer - regression task\n",
    "    linear_combination_regression = np.dot(activation_layer_2, weights[3]) + biases[3]\n",
    "    return linear_combination_layer_1, activation_layer_1, linear_combination_layer_2, activation_layer_2, linear_combination_classification, linear_combination_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_propogation(weights, biases, learning_rate, inputs, y_class, y_reg, z_hidden_1, a_hidden_1, z_hidden_2, a_hidden_2, z_output_class, z_output_reg):\n",
    "    # the number of samples in the dataset\n",
    "    num_samples = y_class.shape[0]\n",
    "    # compute the derivative of the loss function with respect to the output of the network\n",
    "    delta_output_class = sigmoid(z_output_class) - y_class\n",
    "    delta_output_reg = z_output_reg - y_reg\n",
    "    # update the output layer weights and biases for its two tasks\n",
    "    gradient_weights_output_class = np.dot(a_hidden_2.T, delta_output_class)\n",
    "    gradient_biases_output_class = np.sum(delta_output_class, axis=0, keepdims=True)\n",
    "    weights[2] -= learning_rate * gradient_weights_output_class\n",
    "    biases[2] -= learning_rate * gradient_biases_output_class\n",
    "    # derivative of the loss function with respect to the output of the network\n",
    "    gradient_weights_output_reg = np.dot(a_hidden_2.T, delta_output_reg)\n",
    "    gradient_biases_output_reg = np.sum(delta_output_reg, axis=0, keepdims=True)\n",
    "    weights[3] -= learning_rate * gradient_weights_output_reg\n",
    "    biases[3] -= learning_rate * gradient_biases_output_reg\n",
    "    # computing the derivative of the loss function with respect to the output of the second hidden layer\n",
    "    delta_hidden_2 = np.dot(delta_output_class, weights[2].T) + np.dot(delta_output_reg, weights[3].T)\n",
    "    delta_hidden_2 *= tanh_derivative(z_hidden_2)\n",
    "    # updating the weights and biases of the second hidden layer\n",
    "    gradient_weights_hidden_2 = np.dot(a_hidden_1.T, delta_hidden_2)\n",
    "    gradient_biases_hidden_2 = np.sum(delta_hidden_2, axis=0, keepdims=True)\n",
    "    weights[1] -= learning_rate * gradient_weights_hidden_2\n",
    "    biases[1] -= learning_rate * gradient_biases_hidden_2\n",
    "    # computing the derivative of the loss function with respect to the output of the first hidden layer\n",
    "    delta_hidden_1 = np.dot(delta_hidden_2, weights[1].T)\n",
    "    delta_hidden_1 *= sigmoid_derivative(z_hidden_1)\n",
    "    # updating the weights and biases of the first hidden layer\n",
    "    gradient_weights_hidden_1 = np.dot(inputs.T, delta_hidden_1)\n",
    "    gradient_biases_hidden_1 = np.sum(delta_hidden_1, axis=0, keepdims=True)\n",
    "    weights[0] -= learning_rate * gradient_weights_hidden_1\n",
    "    biases[0] -= learning_rate * gradient_biases_hidden_1\n",
    "    # return the updated weights and biases\n",
    "    return weights, biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_multi_task_nn(X_train, y_train_class, y_train_reg, input_size, hidden_sizes, output_sizes, learning_rate, epochs):\n",
    "    # Initialize weights and biases\n",
    "    weights = []\n",
    "    biases = []\n",
    "    sizes = [input_size] + hidden_sizes + output_sizes\n",
    "    # Randomly initialize weights and biases for each layer\n",
    "    weights, biases = initialize_weights(input_size, hidden_sizes, output_sizes)\n",
    "    # Train the model for the given number of epochs\n",
    "    for epoch in range(epochs):\n",
    "        # Forward propagation to get the predicted outputs\n",
    "        z1, a1, z2, a2, z3_class, z3_reg = forward_propogation(X_train, weights, biases)\n",
    "        # Backward propagation to update the weights and biases\n",
    "        weights, biases = backward_propogation(weights, biases, learning_rate, X_train, y_train_class, y_train_reg, z1, a1, z2, a2, z3_class, z3_reg)\n",
    "    # Return the trained weights and biases\n",
    "    return weights, biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(weights, biases, X_test):\n",
    "    # Forward propagation to get the predicted outputs\n",
    "    z1, a1, z2, a2, z3_class, z3_reg = forward_propogation(X_test, weights, biases)\n",
    "    # Return the predicted outputs\n",
    "    return sigmoid(z3_class), z3_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the accuracy of the model\n",
    "def calculate_classification_accuracy(y_true, y_pred):\n",
    "    return accuracy_score(y_true, y_pred)\n",
    "# Calculate the error of the model\n",
    "def calculate_regression_error(y_true, y_pred):\n",
    "    return mean_squared_error(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "Neural_network_model = train_multi_task_nn(X_train, y_train_class, y_train_reg, input_size, hidden_sizes, output_sizes, learning_rate, epochs)\n",
    "y_pred_class, y_pred_reg = predict(Neural_network_model[0], Neural_network_model[1], X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate predictions\n",
    "classification_accuracy = calculate_classification_accuracy(y_val_class, y_pred_class)\n",
    "regression_error = calculate_regression_error(y_val_reg, y_pred_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_accuracy:  0.3333333333333333\n",
      "regression_error:  4.422727809606345e+159\n"
     ]
    }
   ],
   "source": [
    "# printing the results of the model \n",
    "print(\"classification_accuracy: \", classification_accuracy)\n",
    "print(\"regression_error: \", regression_error)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
