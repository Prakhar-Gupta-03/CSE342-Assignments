{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Read the data\n",
    "data = pd.read_csv('glass.csv')\n",
    "# convert the data into numpy array\n",
    "data = data.values "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mahanalobis Distance Computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mahanalobis_distance(X, mean, inverse_covariance):\n",
    "    X = X - mean\n",
    "    result = np.matmul(X, inverse_covariance)\n",
    "    result = np.matmul(result, X.T)\n",
    "    result = np.sqrt(result)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_of_data_points = data.shape[0]\n",
    "# Compute the mean and covariance matrix\n",
    "mean = np.mean(data, axis=0)\n",
    "covariance_matrix = np.cov(data, rowvar=False)\n",
    "inverse_covariance_matrix = np.linalg.inv(covariance_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the Mahalanobis distance for each data point\n",
    "mahanalobis_distances = np.zeros(no_of_data_points)\n",
    "for i in range(no_of_data_points):\n",
    "    mahanalobis_distances[i] = mahanalobis_distance(data[i], mean, inverse_covariance_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorting the Mahalanobis distances in ascending order\n",
    "mahanalobis_distances = np.sort(mahanalobis_distances)\n",
    "# Threshold array stores the threshold value for each index\n",
    "threshold = np.zeros(len(mahanalobis_distances))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Otsu Thresholding for Mahanalobis Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the Otsu threshold value for each index\n",
    "for i in range(1,len(mahanalobis_distances)):\n",
    "    weights = np.zeros(2)\n",
    "    mean = np.zeros(2)\n",
    "    # finding the weights of the two classes\n",
    "    weights[0] = i / len(mahanalobis_distances)\n",
    "    weights[1] = 1 - weights[0]\n",
    "    # we calculate the mean of the two classes and then find the threshold\n",
    "    for j in range(len(mahanalobis_distances)):\n",
    "        if (j<i):\n",
    "            mean[0] += mahanalobis_distances[j]\n",
    "        else:\n",
    "            mean[1] += mahanalobis_distances[j]\n",
    "    mean[0] /= i\n",
    "    mean[1] /= (len(mahanalobis_distances) - i)\n",
    "    # Finding the difference between the two means\n",
    "    mean_difference = mean[0] - mean[1]\n",
    "    weights_product = weights[0] * weights[1]\n",
    "    # Variance between the two classes\n",
    "    variance = weights_product * mean_difference * mean_difference\n",
    "    # Finding the threshold value\n",
    "    threshold[i] = variance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the index of the maximum threshold value\n",
    "max_threshold_index = np.argmax(threshold)\n",
    "# The Otsu threshold value\n",
    "otsu_threshold = mahanalobis_distances[max_threshold_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Otsu threshold value:  4.14316806819999\n",
      "No of outliers:  29\n",
      "No of inliers:  185\n",
      "Intra class variance:  1.531628003617358\n",
      "Inter class variance:  0.0\n",
      "Percentage of outliers:  13.551401869158877 %\n",
      "Percentage of inliers:  86.44859813084112 %\n"
     ]
    }
   ],
   "source": [
    "# finding the no of outliers\n",
    "no_of_outliers = 0\n",
    "for data_point in mahanalobis_distances:\n",
    "    if data_point > otsu_threshold:\n",
    "        no_of_outliers += 1\n",
    "print('Otsu threshold value: ', otsu_threshold)\n",
    "print('No of outliers: ', no_of_outliers)\n",
    "print('No of inliers: ', len(mahanalobis_distances) - no_of_outliers)\n",
    "print('Intra class variance: ', threshold[max_threshold_index])\n",
    "print('Inter class variance: ', threshold[0])\n",
    "print('Percentage of outliers: ', (no_of_outliers / len(mahanalobis_distances)) * 100 , '%')\n",
    "print('Percentage of inliers: ', 100 - ((no_of_outliers / len(mahanalobis_distances)) * 100) , '%')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local Outlier Factor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding the k nearest neighbors for each data point in the data set\n",
    "def k_nearest_neighbors(X, k):\n",
    "    no_of_samples = X.shape[0]\n",
    "    # distance between each pair of data points is stored\n",
    "    distances = np.zeros((no_of_samples, no_of_samples))\n",
    "    # finding the distance between each pair of points\n",
    "    for i in range(no_of_samples):\n",
    "        for j in range(no_of_samples):\n",
    "            distances[i, j] = np.linalg.norm(X[i] - X[j])\n",
    "    knn_indices = np.zeros((no_of_samples, k), dtype=int)\n",
    "    # finding the k nearest neighbors for each data point\n",
    "    for i in range(no_of_samples):\n",
    "        # argsort returns the indices of the sorted array\n",
    "        # 0th index is skipped because it will be the same as the data point\n",
    "        knn_indices[i] = np.argsort(distances[i])[1:k+1]\n",
    "    return knn_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "# computing the reach distance for each data point to its kth nearest neighbor\n",
    "def reach_distance(X, knn_indices):\n",
    "    no_of_samples = X.shape[0]\n",
    "    reach_distances = np.zeros((no_of_samples, no_of_samples))\n",
    "    # finds the reach distance for each data point\n",
    "    for i in range(no_of_samples):\n",
    "        for j in knn_indices[i]:\n",
    "            for k in knn_indices[i]:\n",
    "                # if the data point is not the same as the kth nearest neighbor, then the reach distance is computed\n",
    "                # else the reach distance is set to the distance between the data point and its kth nearest neighbor\n",
    "                if k != j:\n",
    "                    reach_distances[i, j] = max(np.linalg.norm(X[i] - X[j]), reach_distances[i, k])\n",
    "    return reach_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to compute the local reachability density of each sample\n",
    "def lrd(X, knn_indices, reachability_distances, k):\n",
    "    no_of_samples = X.shape[0]\n",
    "    lrd = np.zeros(no_of_samples)\n",
    "    # lrd is computed for each data point\n",
    "    for i in range(no_of_samples):\n",
    "        # the mean of the reachability distances of the k nearest neighbors is computed\n",
    "        for j in range(no_of_samples):\n",
    "            # 1e-10 is added to avoid division by zero \n",
    "            # if the mean is zero, then it will cause division by zero, so adding 1e-10 to avoid the error\n",
    "            lrd[i] = 1 / (np.mean(reachability_distances[i, knn_indices[i]]) + 1e-10)\n",
    "    return lrd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to compute the local outlier factor of each sample\n",
    "def lof(X, knn_indices, lrd):\n",
    "    no_of_samples = X.shape[0]\n",
    "    lof = np.zeros(no_of_samples)\n",
    "    # lof is computed for each data point\n",
    "    for i in range(no_of_samples):\n",
    "        # the ratio of the lrd of the data point to the lrd of its k nearest neighbors is computed\n",
    "        lrd_ratios = np.zeros(k)\n",
    "        for j in range(k):\n",
    "            # for each k nearest neighbor, we calculate the ratio of the lrd of the data point to the lrd of the k nearest neighbor\n",
    "            lrd_ratios[j] = lrd[knn_indices[i][j]] / lrd[i]\n",
    "        # mean of the lrd ratios is the lof value\n",
    "        lof[i] = np.mean(lrd_ratios)\n",
    "    return lof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k is the number of nearest neighbors\n",
    "k = 5\n",
    "k_nearest_neighours = k_nearest_neighbors(data, k)\n",
    "reach_distance = reach_distance(data, k_nearest_neighours)\n",
    "lrd = lrd(data, k_nearest_neighours, reach_distance, k)\n",
    "lof = lof(data, k_nearest_neighours, lrd)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Otsu Thresholding for Local Outlier Factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing the Otsu threshold\n",
    "lof = np.sort(lof)\n",
    "threshold = np.zeros(len(lof))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,len(lof)):\n",
    "    weights = np.zeros(2)\n",
    "    mean = np.zeros(2)\n",
    "    # Finding the weights and mean of each class\n",
    "    weights[0] = i / len(lof)\n",
    "    weights[1] = 1 - weights[0]\n",
    "    for j in range(len(lof)):\n",
    "        if (j < i):\n",
    "            mean[0] += lof[j]\n",
    "        else:\n",
    "            mean[1] += lof[j]\n",
    "    mean[0] /= i\n",
    "    mean[1] /= (len(lof) - i)\n",
    "    mean_difference = mean[0] - mean[1]\n",
    "    # Finding the variance between the two classes\n",
    "    variance = weights[0] * weights[1] * mean_difference * mean_difference\n",
    "    threshold[i] = variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the index of the maximum variance\n",
    "max_threshold_index = np.argmax(threshold)\n",
    "# Otsu threshold using the index of the maximum variance\n",
    "otsu_threshold = lof[max_threshold_index]\n",
    "# finding the no of outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_of_outliers = 0\n",
    "for data_point in lof:\n",
    "    if data_point > otsu_threshold:\n",
    "        no_of_outliers += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Otsu threshold value:  5.079809867042725\n",
      "No of outliers:  3\n",
      "No of inliers: 211\n",
      "Intra class variance:  0.5551403762366578\n",
      "Inter class variance:  0.0\n",
      "Percentage of outliers:  1.4018691588785046 %\n",
      "Percentage of inliers:  98.5981308411215 %\n"
     ]
    }
   ],
   "source": [
    "print('Otsu threshold value: ', otsu_threshold)\n",
    "print('No of outliers: ', no_of_outliers)\n",
    "print('No of inliers:' , len(lof) - no_of_outliers)\n",
    "print('Intra class variance: ', threshold[max_threshold_index])\n",
    "print('Inter class variance: ', threshold[0])\n",
    "print('Percentage of outliers: ', (no_of_outliers / len(lof)) * 100 , '%')\n",
    "print('Percentage of inliers: ', 100 - ((no_of_outliers / len(lof)) * 100) , '%')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
